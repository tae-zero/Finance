from fastapi import FastAPI, Request,HTTPException,Query
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import yfinance as yf
import time
import pandas as pd
from datetime import datetime, timedelta
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from pymongo import MongoClient
from pykrx.stock import get_market_trading_volume_by_date
import json
import os
from pykrx.stock import get_market_trading_value_by_investor
from pykrx import stock


app = FastAPI()

# CORS ë¯¸ë“¤ì›¨ì–´ëŠ” ì•„ë˜ì—ì„œ ì„¤ì •

# CORS ì„¤ì • - ë°°í¬ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (ê°œë°œìš©)
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MongoDB ì—°ê²° - í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
MONGODB_URL = os.getenv("MONGODB_URI", "mongodb://localhost:27017")
print(f"ğŸ” MongoDB URL: {MONGODB_URL[:20]}...")  # ì²˜ìŒ 20ìë§Œ ì¶œë ¥

try:
    client = MongoClient(MONGODB_URL, serverSelectionTimeoutMS=5000)
    # ì—°ê²° í…ŒìŠ¤íŠ¸
    client.admin.command('ping')
    print("âœ… MongoDB ì—°ê²° ì„±ê³µ")
except Exception as e:
    print(f"âŒ MongoDB ì—°ê²° ì‹¤íŒ¨: {e}")
    print(f"âŒ MongoDB URL: {MONGODB_URL}")
    client = None

# í™˜ê²½ ì„¤ì •
ENVIRONMENT = os.getenv("ENVIRONMENT", "development")
DEBUG = os.getenv("DEBUG", "false").lower() == "true"

# OPTIONS ìš”ì²­ì€ FastAPI CORS ë¯¸ë“¤ì›¨ì–´ê°€ ìë™ ì²˜ë¦¬

# Chrome ë“œë¼ì´ë²„ ìë™ ì„¤ì¹˜
def setup_chrome_driver():
    """Railway í™˜ê²½ì—ì„œ Chrome ë“œë¼ì´ë²„ë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •"""
    try:
        # Chrome ê²½ë¡œ ì„¤ì •
        chrome_paths = [
            "/usr/bin/chromium",
            "/usr/bin/chromium-browser", 
            "/usr/bin/google-chrome",
            "/usr/bin/google-chrome-stable"
        ]
        
        chrome_path = None
        for path in chrome_paths:
            if os.path.exists(path):
                chrome_path = path
                break
        
        if chrome_path:
            print(f"Chrome ë°œê²¬: {chrome_path}")
        else:
            print("Chromeì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©")
        
        # Selenium ì„¤ì •
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920x1080')
        options.add_argument('--disable-extensions')
        options.add_argument('--disable-plugins')
        options.add_argument('--disable-images')
        options.add_argument('--disable-javascript')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_argument('--disable-web-security')
        options.add_argument('--allow-running-insecure-content')
        options.add_argument('--remote-debugging-port=9222')
        options.add_argument('--disable-logging')
        options.add_argument('--log-level=3')
        
        if chrome_path:
            options.binary_location = chrome_path
        
        # chromedriver ê²½ë¡œ ì„¤ì •
        chromedriver_paths = [
            "/usr/bin/chromedriver",
            "/usr/local/bin/chromedriver"
        ]
        
        chromedriver_path = None
        for path in chromedriver_paths:
            if os.path.exists(path):
                chromedriver_path = path
                break
        
        if chromedriver_path:
            print(f"ChromeDriver ë°œê²¬: {chromedriver_path}")
            service = Service(chromedriver_path)
        else:
            # webdriver-manager ì‚¬ìš©
            try:
                print("webdriver-managerë¡œ ChromeDriver ì„¤ì¹˜ ì‹œë„...")
                service = Service(ChromeDriverManager().install())
            except Exception as e:
                print(f"webdriver-manager ì‹¤íŒ¨: {e}")
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ê¸°ë³¸ Service ì‚¬ìš©
                service = Service()
        
        driver = webdriver.Chrome(service=service, options=options)
        print("âœ… Chrome ë“œë¼ì´ë²„ ì„±ê³µ")
        return driver
            
    except Exception as e:
        print(f"Chrome ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨: {e}")
        import traceback
        print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None

# MongoDB ì»¬ë ‰ì…˜ ì„¤ì • (ì—°ê²° ì‹¤íŒ¨ ì‹œ None ì²˜ë¦¬)
if client:
    db = client["testDB"]
    collection = db["users"]
    explain = db['explain']
    outline = db['outline']
    industry = db['industry_metrics']
else:
    db = None
    collection = None
    explain = None
    outline = None
    industry = None

#ë°±ì—”ë“œ ë©”ì¸í˜ì´ì§€
@app.get("/")
async def index():
    return {
        "message": "âœ… FastAPI ì„œë²„ ì‹¤í–‰ ì¤‘: /hot /news /price/<ticker> ì‚¬ìš© ê°€ëŠ¥",
        "mongodb_status": "ì—°ê²°ë¨" if client else "ì—°ê²° ì‹¤íŒ¨",
        "environment": ENVIRONMENT
    }

# ì„œë²„ ìƒíƒœ í™•ì¸
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "mongodb": "connected" if client else "disconnected",
        "timestamp": datetime.now().isoformat()
    }


#ê¸°ì—… ìƒì„¸í˜ì´ì§€ ê¸°ì—…ê°œìš”, ê¸°ì—… ì„¤ëª…
@app.get("/company/{name}")
def get_full_company_data(name: str):
    try:
        # URL ë””ì½”ë”© ì²˜ë¦¬ (í•œê¸€ ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
        import urllib.parse
        decoded_name = urllib.parse.unquote(name)
        print(f"ğŸ” ê¸°ì—… ê²€ìƒ‰ ìš”ì²­: {decoded_name}")
        print(f"ğŸ” ì›ë³¸ name: {name}")
        
        if collection is None:
            print("âŒ collectionì´ Noneì…ë‹ˆë‹¤")
            raise HTTPException(status_code=503, detail="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
        
        print(f"ğŸ” MongoDB collection ì‚¬ìš© ê°€ëŠ¥")
        
        # ê¸°ì—…ëª…ìœ¼ë¡œ ê²€ìƒ‰
        base = collection.find_one({"ê¸°ì—…ëª…": decoded_name}, {"_id": 0})
        print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: {base is not None}")
        
        if not base:
            # ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ê²€ìƒ‰ ì‹œë„
            print(f"ğŸ” ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ê²€ìƒ‰ ì‹œë„...")
            base = collection.find_one({"ê¸°ì—…ëª…": {"$regex": decoded_name, "$options": "i"}}, {"_id": 0})
            print(f"ğŸ” ì •ê·œì‹ ê²€ìƒ‰ ê²°ê³¼: {base is not None}")
            
            if not base:
                print(f"âŒ ê¸°ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {decoded_name}")
                raise HTTPException(status_code=404, detail="ê¸°ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        print(f"âœ… ê¸°ì—… ë°ì´í„° ì°¾ìŒ: {base.get('ê¸°ì—…ëª…', 'Unknown')}")

        # 1. ì§§ì€ìš”ì•½ (explain ì»¬ë ‰ì…˜)
        if explain:
            explain_doc = explain.find_one({"ê¸°ì—…ëª…": decoded_name}, {"_id": 0, "ì§§ì€ìš”ì•½": 1})
            if explain_doc:
                base["ì§§ì€ìš”ì•½"] = explain_doc.get("ì§§ì€ìš”ì•½")
                print(f"âœ… ì§§ì€ìš”ì•½ ì¶”ê°€ë¨")

        # 2. outline ì •ë³´ (outline ì»¬ë ‰ì…˜)
        if outline:
            code = base.get("ì¢…ëª©ì½”ë“œ")
            if code:
                outline_doc = outline.find_one({"ì¢…ëª©ì½”ë“œ": code}, {"_id": 0})
                if outline_doc:
                    base["ê°œìš”"] = outline_doc
                    print(f"âœ… ê°œìš” ì •ë³´ ì¶”ê°€ë¨")

        print(f"âœ… ìµœì¢… ë°ì´í„° ë°˜í™˜: {len(str(base))} ë¬¸ì")
        return base
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ê¸°ì—… ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        import traceback
        print(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")

#ê¸°ì—… ì¬ë¬´ì¬í‘œ
@app.get("/companies/names")
def get_all_company_names():
    if collection is None:
        # MongoDB ì—°ê²° ì‹¤íŒ¨ ì‹œ fallback ë°ì´í„° ë°˜í™˜
        print("MongoDB ì—°ê²° ì‹¤íŒ¨, fallback ë°ì´í„° ë°˜í™˜")
        return [
            "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "LGí™”í•™", "í˜„ëŒ€ì°¨", "ë„¤ì´ë²„",
            "ì¹´ì¹´ì˜¤", "LGì „ì", "POSCO", "ê¸°ì•„", "KBê¸ˆìœµ",
            "ì‹ í•œì§€ì£¼", "í•˜ë‚˜ê¸ˆìœµì§€ì£¼", "LGìƒí™œê±´ê°•", "SKí…”ë ˆì½¤", "KT",
            "CJì œì¼ì œë‹¹", "í•œêµ­ì „ë ¥", "í˜„ëŒ€ëª¨ë¹„ìŠ¤", "LGë””ìŠ¤í”Œë ˆì´", "SKì´ë…¸ë² ì´ì…˜"
        ]
    
    try:
        cursor = collection.find({}, {"_id": 0, "ê¸°ì—…ëª…": 1})
        names = [doc["ê¸°ì—…ëª…"] for doc in cursor if "ê¸°ì—…ëª…" in doc]
        if not names:
            # ë°ì´í„°ê°€ ì—†ì„ ë•Œë„ fallback ë°ì´í„° ë°˜í™˜
            return [
                "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "LGí™”í•™", "í˜„ëŒ€ì°¨", "ë„¤ì´ë²„",
                "ì¹´ì¹´ì˜¤", "LGì „ì", "POSCO", "ê¸°ì•„", "KBê¸ˆìœµ"
            ]
        return names
    except Exception as e:
        print(f"ê¸°ì—…ëª… ì¡°íšŒ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ fallback ë°ì´í„° ë°˜í™˜
        return [
            "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "LGí™”í•™", "í˜„ëŒ€ì°¨", "ë„¤ì´ë²„",
            "ì¹´ì¹´ì˜¤", "LGì „ì", "POSCO", "ê¸°ì•„", "KBê¸ˆìœµ"
        ]


# ë©”ì¸í˜ì´ì§€ ì½”ìŠ¤í”¼ í‚¤ì›Œë“œ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
@app.get("/hot/")
async def hot_news():
    try:
        driver = setup_chrome_driver()
        if not driver:
            print("Chrome ë“œë¼ì´ë²„ ì‹¤íŒ¨, ì‹¤ì œ ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹œë„...")
            # Chrome ì—†ì´ë„ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ì‹œë„
            try:
                import requests
                from bs4 import BeautifulSoup
                
                # ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ì½”ìŠ¤í”¼ ê´€ë ¨ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                url = "https://search.naver.com/search.naver?where=news&query=ì½”ìŠ¤í”¼&sort=1"
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
                
                response = requests.get(url, headers=headers, timeout=10)
                soup = BeautifulSoup(response.content, 'html.parser')
                
                news_list = []
                news_items = soup.select('.news_tit')[:5]  # ìƒìœ„ 5ê°œ ë‰´ìŠ¤
                
                for item in news_items:
                    title = item.get_text().strip()
                    link = item.get('href', '#')
                    news_list.append({"title": title, "link": link})
                
                if news_list:
                    print(f"âœ… ì‹¤ì œ ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {len(news_list)}ê°œ")
                    return JSONResponse(content=news_list)
                    
            except Exception as e:
                print(f"ì‹¤ì œ ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            
            # ìµœí›„ì˜ ìˆ˜ë‹¨: fallback ë°ì´í„°
            return JSONResponse(content=[
                {"title": "ì½”ìŠ¤í”¼ ì‹œì¥ ë™í–¥ ë¶„ì„", "link": "#"},
                {"title": "ì£¼ìš” ê¸°ì—… ì‹¤ì  ë°œí‘œ", "link": "#"},
                {"title": "íˆ¬ìì ê´€ì‹¬ì‚¬ ì¦ê°€", "link": "#"},
                {"title": "ì‹œì¥ ì „ë§ ë³´ê³ ì„œ", "link": "#"},
                {"title": "ê¸ˆìœµ ì •ì±… ë³€í™”", "link": "#"}
            ])

        driver.get('https://search.daum.net/nate?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q=ì½”ìŠ¤í”¼')

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        driver.quit()

        path = '#dnsColl > div:nth-child(1) > ul > li > div.c-item-content > div > div.item-title > strong > a'
        a_tags = soup.select(path)

        news_list = [{"title": a.text.strip(), "link": a['href']} for a in a_tags[:5]]
        return JSONResponse(content=news_list)
    except Exception as e:
        print(f"í•«ë‰´ìŠ¤ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(content={"error": f"í•«ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}, status_code=500)

# ë©”ì¸í˜ì´ì§€ ì‹¤ì  ë°œí‘œ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
@app.get("/main_news/")
async def main_news():
    driver = setup_chrome_driver()
    if not driver:
        print("Chrome ë“œë¼ì´ë²„ ì‹¤íŒ¨, ì‹¤ì œ ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹œë„...")
        # Chrome ì—†ì´ë„ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ì‹œë„
        try:
            import requests
            from bs4 import BeautifulSoup
            
            # ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ì‹¤ì  ë°œí‘œ ê´€ë ¨ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            url = "https://search.naver.com/search.naver?where=news&query=ì‹¤ì  ë°œí‘œ&sort=1"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            news_list = []
            news_items = soup.select('.news_tit')[:5]  # ìƒìœ„ 5ê°œ ë‰´ìŠ¤
            
            for item in news_items:
                title = item.get_text().strip()
                link = item.get('href', '#')
                news_list.append({"title": title, "link": link})
            
            if news_list:
                print(f"âœ… ì‹¤ì œ ì‹¤ì ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {len(news_list)}ê°œ")
                return JSONResponse(content=news_list)
                
        except Exception as e:
            print(f"ì‹¤ì œ ì‹¤ì ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        
        # ìµœí›„ì˜ ìˆ˜ë‹¨: fallback ë°ì´í„°
        return JSONResponse(content=[
            {"title": "ì‚¼ì„±ì „ì 3ë¶„ê¸° ì‹¤ì  ë°œí‘œ", "link": "#"},
            {"title": "SKí•˜ì´ë‹‰ìŠ¤ ë§¤ì¶œ ì¦ê°€", "link": "#"},
            {"title": "LGí™”í•™ ì‹ ì‚¬ì—… í™•ì¥", "link": "#"},
            {"title": "í˜„ëŒ€ì°¨ ì „ê¸°ì°¨ íŒë§¤ ê¸‰ì¦", "link": "#"},
            {"title": "ë„¤ì´ë²„ í´ë¼ìš°ë“œ ì‚¬ì—… ì„±ì¥", "link": "#"}
        ])

    driver.get('https://search.daum.net/nate?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q=ì‹¤ì  ë°œí‘œ')

    soup = BeautifulSoup(driver.page_source, 'html.parser')
    driver.quit()

    path = '#dnsColl > div:nth-child(1) > ul > li > div.c-item-content > div > div.item-title > strong > a'
    a_tags = soup.select(path)

    news_list = [{"title": a.text.strip(), "link": a['href']} for a in a_tags[:5]]
    return JSONResponse(content=news_list)


# ê¸°ì—… ìƒì„¸í˜ì´ì§€ í•´ë‹¹ ê¸°ì—… í‚¤ì›Œë“œ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
@app.get("/news/")
async def search_news(request: Request):
    keyword = request.query_params.get('keyword')
    if not keyword:
        return JSONResponse(content={"error": "keyword íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}, status_code=400)

    driver = setup_chrome_driver()
    if not driver:
        # Chrome ë“œë¼ì´ë²„ ì‹¤íŒ¨ ì‹œ fallback ë°ì´í„° ë°˜í™˜
        print("Chrome ë“œë¼ì´ë²„ ì‹¤íŒ¨, fallback ë°ì´í„° ë°˜í™˜")
        return JSONResponse(content=[
            {"title": f"{keyword} ê´€ë ¨ ë‰´ìŠ¤ 1", "link": "#"},
            {"title": f"{keyword} ê´€ë ¨ ë‰´ìŠ¤ 2", "link": "#"},
            {"title": f"{keyword} ê´€ë ¨ ë‰´ìŠ¤ 3", "link": "#"},
            {"title": f"{keyword} ê´€ë ¨ ë‰´ìŠ¤ 4", "link": "#"},
            {"title": f"{keyword} ê´€ë ¨ ë‰´ìŠ¤ 5", "link": "#"}
        ])
    search_url = f'https://search.daum.net/nate?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q={keyword}'
    driver.get(search_url)
    time.sleep(2)

    soup = BeautifulSoup(driver.page_source, 'html.parser')
    driver.quit()

    a_tags = soup.select('#dnsColl > div:nth-child(1) > ul > li > div.c-item-content > div > div.item-title > strong > a')
    print(f"'{keyword}' ë‰´ìŠ¤ ê°œìˆ˜: {len(a_tags)}")

    news_list = [{"title": a.text.strip(), "link": a['href']} for a in a_tags[:10]]
    return JSONResponse(content=news_list)


# ê¸°ì—…ìƒì„¸í˜ì´ì§€ í•´ë‹¹ ê¸°ì—… ì£¼ê°€ ì‹œì„¸
@app.get("/price/{ticker}")
def get_price_data(ticker: str):
    try:
        # yfinanceë¡œ ë°ì´í„° ë°›ê¸°
        df = yf.download(ticker, period="3y", interval="1d")

        if df.empty:
            return {"error": "ë°ì´í„° ì—†ìŒ"}

        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ í›„ ì¸ë±ìŠ¤ ë¦¬ì…‹
        df = df[['Close']].reset_index()

        # Date ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        df['Date'] = df['Date'].astype(str)

        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ JSON friendlyë¡œ êµ¬ì„±
        result = [{"Date": row['Date'], "Close": float(row['Close'])} for _, row in df.iterrows()]
        return result

    except Exception as e:
        return {"error": str(e)}


# ê¸°ì—…ìƒì„¸í˜ì´ì§€ ì¢…ëª©ë¶„ì„ ë¦¬í¬íŠ¸
@app.get("/report/")
def get_report_summary(code: str = Query(..., description="ì¢…ëª© ì½”ë“œ (ì˜ˆ: A005930)")):
    driver = setup_chrome_driver()
    if not driver:
        # Chrome ë“œë¼ì´ë²„ ì‹¤íŒ¨ ì‹œ fallback ë°ì´í„° ë°˜í™˜
        print("Chrome ë“œë¼ì´ë²„ ì‹¤íŒ¨, fallback ë°ì´í„° ë°˜í™˜")
        return [
            {
                "date": "2024-01-15",
                "title": "ì¢…ëª© ë¶„ì„ ë¦¬í¬íŠ¸",
                "summary": "íˆ¬ì ì˜ê²¬: ë§¤ìˆ˜ / ëª©í‘œì£¼ê°€: 100,000ì›",
                "opinion": "ë§¤ìˆ˜",
                "target_price": "100,000",
                "closing_price": "95,000",
                "analyst": "ì¦ê¶Œì‚¬A"
            }
        ]

    url = f"https://comp.fnguide.com/SVO2/ASP/SVD_Consensus.asp?pGB=1&gicode={code}&MenuYn=Y&ReportGB=&NewMenuID=108"
    driver.get(url)
    time.sleep(2)

    data = []
    try:
        rows = driver.find_elements(By.XPATH, '//*[@id="bodycontent4"]/tr')
        for row in rows:
            try:
                date = row.find_element(By.XPATH, './td[1]').text.strip()
                title = row.find_element(By.XPATH, './td[2]//span[@class="txt2"]').text.strip()
                summary_parts = row.find_elements(By.XPATH, './td[2]//dd')
                summary = " / ".join([p.text.strip() for p in summary_parts if p.text.strip()])

                # ì¶”ê°€ í•­ëª©: íˆ¬ìì˜ê²¬, ëª©í‘œì£¼ê°€, ì „ì¼ì¢…ê°€
                opinion = ""
                try:
                    opinion = row.find_element(By.XPATH, './td[3]/span').text[1].strip()
                except:
                    pass

                target_price = ""
                try:
                    target_price = row.find_element(By.XPATH, './td[4]/span').text.strip()
                except:
                    pass

                closing_price = ""
                try:
                    closing_price = row.find_element(By.XPATH, './td[5]').text.strip()
                except:
                    pass

                analyst = ""
                try:
                    analyst = row.find_element(By.XPATH, './td[6]').text.strip()
                except:
                    pass

                data.append({
                    "date": date,
                    "title": title,
                    "summary": summary,
                    "opinion": opinion,
                    "target_price": target_price,
                    "closing_price": closing_price,
                    "analyst": analyst
                })

                if len(data) >= 5:
                    break

            except Exception as e:
                print("âš ï¸ í–‰ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
                continue
    finally:
        driver.quit()

    return data



# ë©”ì¸í˜ì´ì§€ ì½”ìŠ¤í”¼ ì§€ìˆ˜
@app.get("/kospi/")
def get_kospi_data():
    try:
        # ì˜¤ëŠ˜ ë‚ ì§œ ê³„ì‚°
        today = datetime.today().date()
        
        # ë” ê°•ë ¥í•œ yfinance ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        df = None
        
        # 1ë‹¨ê³„: ë‹¤ì–‘í•œ ì‹¬ë³¼ê³¼ ì„¤ì •ìœ¼ë¡œ ì‹œë„
        symbols_and_configs = [
            ("^KS11", {"period": "1y", "interval": "1d"}),
            ("KS11", {"period": "1y", "interval": "1d"}),
            ("^KS11", {"period": "6mo", "interval": "1d"}),
            ("^KS11", {"period": "3mo", "interval": "1d"}),
            ("^KS11", {"period": "1mo", "interval": "1d"}),
        ]
        
        for symbol, config in symbols_and_configs:
            try:
                print(f"yfinance ì‹œë„: {symbol}, ì„¤ì •: {config}")
                
                # ë°©ë²• 1: yf.download ì‚¬ìš©
                df = yf.download(
                    symbol, 
                    period=config["period"], 
                    interval=config["interval"], 
                    auto_adjust=True, 
                    progress=False,
                    threads=False,  # ìŠ¤ë ˆë“œ ë¹„í™œì„±í™”ë¡œ ì•ˆì •ì„± í–¥ìƒ
                    group_by="ticker"
                )
                
                print(f"ë°ì´í„°í”„ë ˆì„ ì •ë³´: shape={df.shape}, empty={df.empty}")
                if not df.empty:
                    print(f"âœ… yf.download ì„±ê³µ: {symbol}, ë°ì´í„° ê°œìˆ˜: {len(df)}")
                    print(f"ì»¬ëŸ¼: {df.columns.tolist()}")
                    print(f"ì²« 5í–‰:\n{df.head()}")
                    break
                else:
                    print(f"âš ï¸ ë¹ˆ ë°ì´í„°í”„ë ˆì„: {symbol}")
                    
            except Exception as e:
                print(f"âŒ yf.download ì‹¤íŒ¨: {symbol} - {type(e).__name__}: {e}")
                import traceback
                print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                continue
        
        # 2ë‹¨ê³„: Ticker ê°ì²´ë¡œ ì‹œë„
        if df is None or df.empty:
            for symbol in ["^KS11", "KS11"]:
                try:
                    print(f"Ticker ê°ì²´ ì‹œë„: {symbol}")
                    ticker = yf.Ticker(symbol)
                    
                    # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì‹œë„
                    for method in ["history", "download"]:
                        try:
                            if method == "history":
                                df = ticker.history(period="1y", interval="1d", auto_adjust=True)
                            else:
                                df = ticker.download(period="1y", interval="1d", auto_adjust=True)
                            
                            if not df.empty:
                                print(f"âœ… Ticker.{method} ì„±ê³µ: {symbol}")
                                break
                        except Exception as e:
                            print(f"âŒ Ticker.{method} ì‹¤íŒ¨: {e}")
                            continue
                    
                    if df is not None and not df.empty:
                        break
                        
                except Exception as e:
                    print(f"âŒ Ticker ê°ì²´ ìƒì„± ì‹¤íŒ¨: {symbol} - {e}")
                    continue
        
        # 3ë‹¨ê³„: ëŒ€ì•ˆ ë°ì´í„° ì†ŒìŠ¤ ì‹œë„
        if df is None or df.empty:
            print("âš ï¸ yfinance ì‹¤íŒ¨, ëŒ€ì•ˆ ë°ì´í„° ì†ŒìŠ¤ ì‹œë„...")
            
            # ëŒ€ì•ˆ 1: ë‹¤ë¥¸ ì‹¬ë³¼ë“¤ ì‹œë„
            alternative_symbols = ["EWY", "FXI", "EWJ"]  # í•œêµ­, ì¤‘êµ­, ì¼ë³¸ ETF
            for alt_symbol in alternative_symbols:
                try:
                    print(f"ëŒ€ì•ˆ ì‹¬ë³¼ ì‹œë„: {alt_symbol}")
                    df = yf.download(alt_symbol, period="1y", interval="1d", auto_adjust=True, progress=False)
                    if not df.empty:
                        print(f"âœ… ëŒ€ì•ˆ ì‹¬ë³¼ ì„±ê³µ: {alt_symbol}")
                        break
                except Exception as e:
                    print(f"âŒ ëŒ€ì•ˆ ì‹¬ë³¼ ì‹¤íŒ¨: {alt_symbol} - {e}")
                    continue
        
        # 4ë‹¨ê³„: ìˆ˜ë™ìœ¼ë¡œ ë°ì´í„° ìƒì„± (ì‹¤ì œ KOSPIì™€ ìœ ì‚¬í•œ íŒ¨í„´)
        if df is None or df.empty:
            print("âš ï¸ ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ ì‹¤íŒ¨, ì‹¤ì œ KOSPI íŒ¨í„´ ê¸°ë°˜ ê°€ìƒ ë°ì´í„° ìƒì„±")
            
            # ì‹¤ì œ KOSPIì™€ ìœ ì‚¬í•œ íŒ¨í„´ìœ¼ë¡œ ë°ì´í„° ìƒì„±
            import random
            base_price = 2500
            dates = []
            closes = []
            
            for i in range(30, 0, -1):
                date = today - timedelta(days=i)
                # ì£¼ë§ ì œì™¸
                if date.weekday() < 5:  # ì›”ìš”ì¼(0) ~ ê¸ˆìš”ì¼(4)
                    dates.append(date.strftime('%Y-%m-%d'))
                    # ì‹¤ì œ ì£¼ì‹ê³¼ ìœ ì‚¬í•œ ë³€ë™ì„± ì ìš©
                    change = random.uniform(-50, 50)
                    base_price += change
                    closes.append(round(base_price, 2))
            
            return JSONResponse(content=[{"Date": date, "Close": close} for date, close in zip(dates, closes)])
        
        # ìµœì¢… fallback: ê°€ìƒ ë°ì´í„° ìƒì„±
        if df is None or df.empty:
            print("âš ï¸ ëª¨ë“  yfinance ì‹œë„ ì‹¤íŒ¨, ê°€ìƒ ë°ì´í„° ìƒì„±")
            dates = [(today - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(30, 0, -1)]
            closes = [2500 + i * 2 + (i % 7) * 10 for i in range(30)]
            return JSONResponse(content=[{"Date": date, "Close": close} for date, close in zip(dates, closes)])

        # Close ì»¬ëŸ¼ ì°¾ê¸°
        close_col = None
        for col in df.columns:
            if isinstance(col, tuple):
                if "Close" in col:
                    close_col = col
                    break
            elif col == "Close":
                close_col = col
                break

        if close_col is None:
            return JSONResponse(content={"error": f"Close ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì»¬ëŸ¼ ëª©ë¡: {df.columns.tolist()}"}, status_code=400)

        df = df[[close_col]].reset_index()
        df.columns = ['Date', 'Close']
        df['Date'] = df['Date'].astype(str)
        df['Close'] = df['Close'].astype(float)

        return JSONResponse(content=df.to_dict(orient="records"))

    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)


# 0ì„ ì œì™¸í•œ í•´ë‹¹ ê¸°ì—… ì¢…ëª© ì¬ë¬´ì œí‘œ ë¦¬ìŠ¤íŠ¸
@app.get("/sales/{name}")
def get_sales_by_name(name: str):
    df = pd.read_csv("NICE_ë‚´ìˆ˜ìˆ˜ì¶œ_ì½”ìŠ¤í”¼.csv")
    grouped = df.groupby(['ì¢…ëª©ëª…', 'ì‚¬ì—…ë¶€ë¬¸', 'ë§¤ì¶œí’ˆëª©ëª…', 'êµ¬ë¶„'])[['2022_12 ë§¤ì¶œì•¡', '2023_12 ë§¤ì¶œì•¡', '2024_12 ë§¤ì¶œì•¡']].sum()

    if name not in grouped.index.get_level_values(0):
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ê¸°ì—… ì—†ìŒ")

    filtered = grouped.loc[name].reset_index()
    return filtered.to_dict(orient="records")

# ê¸°ì—…ìƒì„¸í”¼ì´ì§€ í•´ë‹¹ê¸°ì—… ê¸°ê´€, ì™¸êµ­ì¸, ê¸°ê´€ ë§¤ìˆ˜,ë§¤ë„ëŸ‰
@app.get("/investors/")
def get_investor_summary(ticker: str = Query(..., description="ì¢…ëª© ì½”ë“œ (ì˜ˆ: 005930)")):
    try:
        # ê¸°ê°„ ì„¤ì •: ì˜¤ëŠ˜ ~ 3ê°œì›” ì „
        end = datetime.today()
        start = end - timedelta(days=10)

        # ë‚ ì§œ í¬ë§·
        start_str = start.strftime("%Y%m%d")
        end_str = end.strftime("%Y%m%d")

        # ë°ì´í„° ì¡°íšŒ
        df = get_market_trading_volume_by_date(start_str, end_str, ticker)

        if df.empty:
            return {"error": "ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

        # ë‚ ì§œ ì¸ë±ìŠ¤ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ
        df.reset_index(inplace=True)
        df.rename(columns={"ë‚ ì§œ": "date"}, inplace=True)

        # ê¸°íƒ€ë²•ì¸ ì»¬ëŸ¼ ì œê±° (ìˆì„ ê²½ìš°)
        remove_cols = ["ê¸°íƒ€ë²•ì¸"]
        for col in remove_cols:
            if col in df.columns:
                df.drop(columns=[col], inplace=True)

        # ìˆ«ìí˜• ë³€í™˜
        for col in df.columns:
            if col != "date":
                df[col] = df[col].astype(int)

        # JSON ë³€í™˜
        return df.to_dict(orient="records")

    except Exception as e:
        return {"error": str(e)}


# ë©”ì¸í˜ì´ì§€ ì‚°ì—…ë³„ ì¬ë¬´ì§€í‘œ ë¶„ì„ ì •ë³´ ì¡°íšŒ
@app.get("/industry/{name}")
def get_industry_analysis(name: str):
    try:
        with open("ì‚°ì—…ë³„ì„¤ëª….json", encoding="utf-8") as f:
            data = json.load(f)
        name = name.strip()
        for item in data:
            if item.get("industry") == name:
                return item
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì‚°ì—… ì •ë³´ ì—†ìŒ")
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="ì‚°ì—…ë³„ì„¤ëª….json íŒŒì¼ ì—†ìŒ")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")


# ë©”ì¸í˜ì´ì§€ ê¸°ì—… ì¬ë¬´ì§€í‘œ JSON
@app.get("/company_metrics/{name}")
def get_company_metrics(name: str):
    try:
        with open("ê¸°ì—…ë³„_ì¬ë¬´ì§€í‘œ.json", "r", encoding="utf-8") as f:
            data = json.load(f)
        if name in data:
            return JSONResponse(content=data[name])
        else:
            raise HTTPException(status_code=404, detail="í•´ë‹¹ ê¸°ì—… ì§€í‘œ ì—†ìŒ")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))




# ë©”ì¸í˜ì´ì§€ íˆ¬ììë³„ ë§¤ìˆ˜, ë§¤ë„ëŸ‰ ì½”ìŠ¤í”¼ ì´ ê¸°ì¤€
@app.get("/investor/value/")
def get_kospi_investor_value():
    try:
        # ìµœê·¼ 10ì¼ ë‚ ì§œ ê³„ì‚°
        end_date = datetime.today()
        start_date = end_date - timedelta(days=10)

        start = start_date.strftime("%Y%m%d")
        end = end_date.strftime("%Y%m%d")

        # pykrx ë°ì´í„°
        df = get_market_trading_value_by_investor(start, end, "KOSPI")

        # ë‚ ì§œ ì¸ë±ìŠ¤ê°€ ë§ëŠ”ì§€ í™•ì¸í•˜ê³  ë³€í™˜
        try:
            df.index = pd.to_datetime(df.index, format="%Y%m%d")
            df.index = df.index.strftime('%Y-%m-%d')
            df = df.reset_index(names="ë‚ ì§œ")
        except:
            df = df.reset_index()  # fallback

        return df.to_dict(orient="records")

    except Exception as e:
        return {"error": str(e)}



# ë©”ì¸í˜ì´ì§€ ë§¤ì¶œì•¡, DPS, ì˜ì—…ì´ìµë¥  ìƒìœ„ 5ê°œ ë¦¬ìŠ¤íŠ¸
@app.get("/rankings/")
def get_top_rankings():
    try:
        # MongoDBì—ì„œ í•„ìš”í•œ ë°ì´í„°ë§Œ ì¡°íšŒ
        cursor = collection.find({
            "ì§€í‘œ.2024/12_ë§¤ì¶œì•¡": {"$exists": True},
            "ì§€í‘œ.2024/12_DPS": {"$exists": True},
            "ì§€í‘œ.2024/12_ì˜ì—…ì´ìµë¥ ": {"$exists": True}

        }, {
            "ê¸°ì—…ëª…": 1,
            "ì§€í‘œ.2024/12_ë§¤ì¶œì•¡": 1,
            "ì§€í‘œ.2024/12_DPS": 1,
            "ì§€í‘œ.2024/12_ì˜ì—…ì´ìµë¥ ": 1

        })

        df = pd.json_normalize(list(cursor)).rename(columns={
            "ê¸°ì—…ëª…": "ê¸°ì—…ëª…",
            "ì§€í‘œ.2024/12_ë§¤ì¶œì•¡": "ë§¤ì¶œì•¡",
            "ì§€í‘œ.2024/12_DPS": "DPS",
            "ì§€í‘œ.2024/12_ì˜ì—…ì´ìµë¥ ": "ì˜ì—…ì´ìµë¥ "

        })

        # ìˆ«ì ë³€í™˜
        for col in ["ë§¤ì¶œì•¡", "DPS", "ì˜ì—…ì´ìµë¥ "]:
            df[col] = pd.to_numeric(df[col], errors="coerce")

        # ê°ê° ìƒìœ„ 5ê°œ ì¶”ì¶œ
        result = {
            "ë§¤ì¶œì•¡_TOP5": df.nlargest(5, "ë§¤ì¶œì•¡")[["ê¸°ì—…ëª…", "ë§¤ì¶œì•¡"]].to_dict(orient="records"),
            "DPS_TOP5": df.nlargest(5, "DPS")[["ê¸°ì—…ëª…", "DPS"]].to_dict(orient="records"),
            "ì˜ì—…ì´ìµë¥ _TOP5": df.nlargest(5, "ì˜ì—…ì´ìµë¥ ")[["ê¸°ì—…ëª…", "ì˜ì—…ì´ìµë¥ "]].to_dict(orient="records"),

        }

        return result

    except Exception as e:
        return {"error": str(e)}

#ì‹œê°€ì´ì•¡ top 10
@app.get("/marketcap/")
def get_marketcap_top10():
    try:
        today = datetime.today().strftime("%Y%m%d")

        # KOSPI ì‹œê°€ì´ì•¡ ì „ì²´ ì¢…ëª© ë¶ˆëŸ¬ì˜¤ê¸°
        df = stock.get_market_cap_by_ticker(today, market="KOSPI")

        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        df = df.reset_index()[["í‹°ì»¤", "ì‹œê°€ì´ì•¡", "ì¢…ê°€"]]
        df["ê¸°ì—…ëª…"] = df["í‹°ì»¤"].apply(lambda x: stock.get_market_ticker_name(x))

        # ìƒìœ„ 10ê°œ ê¸°ì—… ì •ë ¬
        df = df.sort_values(by="ì‹œê°€ì´ì•¡", ascending=False).head(10)

        # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
        df = df[["ê¸°ì—…ëª…", "í‹°ì»¤", "ì‹œê°€ì´ì•¡", "ì¢…ê°€"]]

        return {"ì‹œê°€ì´ì•¡_TOP10": df.to_dict(orient="records")}

    except Exception as e:
        return {"error": str(e)}

# ê±°ë˜ëŸ‰ top5
@app.get("/top_volume")
def get_top_volume():
    try:
        today = datetime.today().strftime("%Y%m%d")

        # KOSPI ì¢…ëª© ì „ì²´ OHLCV ë°ì´í„°
        df = stock.get_market_ohlcv(today, market="KOSPI")

        # ê±°ë˜ëŸ‰ ìƒìœ„ 5ê°œ
        top5 = df.sort_values(by="ê±°ë˜ëŸ‰", ascending=False).head(5)
        top5["ì¢…ëª©ì½”ë“œ"] = top5.index
        top5["ì¢…ëª©ëª…"] = top5["ì¢…ëª©ì½”ë“œ"].apply(lambda code: stock.get_market_ticker_name(code))
        top5.reset_index(drop=True, inplace=True)

        # JSON í˜•íƒœë¡œ ë°˜í™˜
        result = top5[["ì¢…ëª©ëª…", "ì¢…ëª©ì½”ë“œ", "ê±°ë˜ëŸ‰"]].to_dict(orient="records")
        return JSONResponse(content=result)

    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)

# ì£¼ë¦°ì´ë“¤ì„ ìœ„í•œ ë³´ë¬¼ì°¾ê¸°
from fastapi import FastAPI
from fastapi.responses import JSONResponse

@app.get("/api/treasure")
def get_treasure_data():
    docs = list(collection.find({}, {
        "_id": 0,
        "ê¸°ì—…ëª…": 1,
        "ì—…ì¢…ëª…": 1,
        "ì§€í‘œ": 1
    }))

    years = ["2022", "2023", "2024"]
    result = []

    for doc in docs:
        ê¸°ì—…ëª… = doc.get("ê¸°ì—…ëª…", "ì•Œ ìˆ˜ ì—†ìŒ")
        ì—…ì¢…ëª… = doc.get("ì—…ì¢…ëª…", "ì•Œ ìˆ˜ ì—†ìŒ")
        ì§€í‘œ = doc.get("ì§€í‘œ", {})

        try:
            per = {}
            pbr = {}
            roe = {}
            mktcap = {}
            equity = {}         # âœ… ì§€ë°°ì£¼ì£¼ì§€ë¶„ (ì‹ ê·œ)
            owner_income = {}   # âœ… ì§€ë°°ì£¼ì£¼ìˆœì´ìµ (ì‹ ê·œ)

            for year in years:
                per[year] = ì§€í‘œ.get(f"{year}/12_PER")
                pbr[year] = ì§€í‘œ.get(f"{year}/12_PBR")
                roe[year] = ì§€í‘œ.get(f"{year}/12_ROE")
                mktcap[year] = ì§€í‘œ.get(f"{year}/12_ì‹œê°€ì´ì•¡")
                equity[year] = ì§€í‘œ.get(f"{year}/12_ì§€ë°°ì£¼ì£¼ì§€ë¶„")
                owner_income[year] = ì§€í‘œ.get(f"{year}/12_ì§€ë°°ì£¼ì£¼ìˆœì´ìµ")

            result.append({
                "ê¸°ì—…ëª…": ê¸°ì—…ëª…,
                "ì—…ì¢…ëª…": ì—…ì¢…ëª…,
                "PER": per,
                "PBR": pbr,
                "ROE": roe,
                "ì‹œê°€ì´ì•¡": mktcap,
                "ì§€ë°°ì£¼ì£¼ì§€ë¶„": equity,             # âœ… ì¶”ê°€ë¨
                "ì§€ë°°ì£¼ì£¼ìˆœì´ìµ": owner_income       # âœ… ì¶”ê°€ë¨
            })
        except Exception as e:
            print(f"âŒ {ê¸°ì—…ëª…} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:", e)

    
    return JSONResponse(content=result)


# uvicorn main:app --reload

