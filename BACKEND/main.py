from fastapi import FastAPI, Request,HTTPException,Query
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from bs4 import BeautifulSoup
import yfinance as yf
import time
import pandas as pd
from datetime import datetime, timedelta
import requests
from pymongo import MongoClient
from pykrx.stock import get_market_trading_volume_by_date
import json
import os
from pykrx.stock import get_market_trading_value_by_investor
from pykrx import stock


app = FastAPI()

# CORS ë¯¸ë“¤ì›¨ì–´ëŠ” ì•„ë˜ì—ì„œ ì„¤ì •

# CORS ì„¤ì • - ë°°í¬ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (ê°œë°œìš©)
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MongoDB ì—°ê²° - í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
print(f"ğŸ” í™˜ê²½ë³€ìˆ˜ í™•ì¸:")
print(f"ğŸ” MONGODB_URI: {os.getenv('MONGODB_URI', 'NOT_SET')}")
print(f"ğŸ” MONGODB_URL: {os.getenv('MONGODB_URL', 'NOT_SET')}")

# MongoDB URL ìš°ì„ ìˆœìœ„: MONGODB_URL > MONGODB_URI > ê¸°ë³¸ê°’ (MONGODB_URLì´ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìŒ)
MONGODB_URL = os.getenv("MONGODB_URL") or os.getenv("MONGODB_URI") or "mongodb://localhost:27017"
print(f"ğŸ” ìµœì¢… MongoDB URL: {MONGODB_URL[:30]}...")  # ì²˜ìŒ 30ìë§Œ ì¶œë ¥

try:
    client = MongoClient(MONGODB_URL, serverSelectionTimeoutMS=5000)
    # ì—°ê²° í…ŒìŠ¤íŠ¸
    client.admin.command('ping')
    print("âœ… MongoDB ì—°ê²° ì„±ê³µ")
except Exception as e:
    print(f"âŒ MongoDB ì—°ê²° ì‹¤íŒ¨: {e}")
    print(f"âŒ MongoDB URL: {MONGODB_URL}")
    client = None

# í™˜ê²½ ì„¤ì •
ENVIRONMENT = os.getenv("ENVIRONMENT", "development")
DEBUG = os.getenv("DEBUG", "false").lower() == "true"

# OPTIONS ìš”ì²­ì€ FastAPI CORS ë¯¸ë“¤ì›¨ì–´ê°€ ìë™ ì²˜ë¦¬

# ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ í—¬í¼ í•¨ìˆ˜
def scrape_news_with_requests(url: str, keyword: str = ""):
    """requestsì™€ BeautifulSoupì„ ì‚¬ìš©í•œ ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        
        news_list = []
        # ì—¬ëŸ¬ ì„ íƒì ì‹œë„
        selectors = [
            'a.tit_main',
            '.tit_main',
            '.news_tit',
            '.news_area .news_tit',
            '.item-title > strong > a',
            '#dnsColl .item-title strong a'
        ]
        
        news_items = []
        for selector in selectors:
            news_items = soup.select(selector)
            if news_items:
                print(f"âœ… ì„ íƒì {selector}ë¡œ {len(news_items)}ê°œ ë‰´ìŠ¤ ë°œê²¬")
                break
        
        if not news_items:
            # ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì‹œë„
            news_items = soup.find_all('a', class_='tit_main')
            if not news_items:
                news_items = soup.find_all('a', href=lambda x: x and 'news' in x)
        
        for item in news_items[:5]:
            try:
                title = item.get_text().strip()
                link = item.get('href', '#')
                if title and len(title) > 5:
                    news_list.append({"title": title, "link": link})
            except:
                continue
        
        return news_list
        
    except Exception as e:
        print(f"âŒ ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        return []

# MongoDB ì»¬ë ‰ì…˜ ì„¤ì • (ì—°ê²° ì‹¤íŒ¨ ì‹œ None ì²˜ë¦¬)
if client:
    try:
        db = client["testDB"]
        collection = db["users"]
        explain = db['explain']
        outline = db['outline']
        industry = db['industry_metrics']
        kospi_cache = db['kospi_cache']  # KOSPI ë°ì´í„° ìºì‹±ìš©
        print(f"âœ… MongoDB ì»¬ë ‰ì…˜ ì„¤ì • ì™„ë£Œ")
        print(f"âœ… collection: {collection}")
        print(f"âœ… explain: {explain}")
        print(f"âœ… outline: {outline}")
        print(f"âœ… kospi_cache: {kospi_cache}")
    except Exception as e:
        print(f"âŒ MongoDB ì»¬ë ‰ì…˜ ì„¤ì • ì‹¤íŒ¨: {e}")
        db = None
        collection = None
        explain = None
        outline = None
        industry = None
        kospi_cache = None
else:
    print("âŒ MongoDB í´ë¼ì´ì–¸íŠ¸ê°€ Noneì…ë‹ˆë‹¤")
    db = None
    collection = None
    explain = None
    outline = None
    industry = None
    kospi_cache = None

#ë°±ì—”ë“œ ë©”ì¸í˜ì´ì§€
@app.get("/")
async def index():
    return {
        "message": "âœ… FastAPI ì„œë²„ ì‹¤í–‰ ì¤‘: /hot /news /price/<ticker> ì‚¬ìš© ê°€ëŠ¥",
        "mongodb_status": "ì—°ê²°ë¨" if client else "ì—°ê²° ì‹¤íŒ¨",
        "environment": ENVIRONMENT
    }

# ì„œë²„ ìƒíƒœ í™•ì¸
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "mongodb": "connected" if client else "disconnected",
        "timestamp": datetime.now().isoformat()
    }


#ê¸°ì—… ìƒì„¸í˜ì´ì§€ ê¸°ì—…ê°œìš”, ê¸°ì—… ì„¤ëª…
@app.get("/company/{name}")
def get_full_company_data(name: str):
    try:
        # URL ë””ì½”ë”© ì²˜ë¦¬ (í•œê¸€ ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
        import urllib.parse
        decoded_name = urllib.parse.unquote(name)
        print(f"ğŸ” ê¸°ì—… ê²€ìƒ‰ ìš”ì²­: {decoded_name}")
        print(f"ğŸ” ì›ë³¸ name: {name}")
        
        if collection is None:
            print("âŒ collectionì´ Noneì…ë‹ˆë‹¤")
            print("âŒ MongoDB ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”")
            raise HTTPException(status_code=503, detail="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
        
        print(f"ğŸ” MongoDB collection ì‚¬ìš© ê°€ëŠ¥")
        
        # ê¸°ì—…ëª…ìœ¼ë¡œ ê²€ìƒ‰
        base = collection.find_one({"ê¸°ì—…ëª…": decoded_name}, {"_id": 0})
        print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: {base is not None}")
        
        if not base:
            # ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ê²€ìƒ‰ ì‹œë„
            print(f"ğŸ” ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ê²€ìƒ‰ ì‹œë„...")
            base = collection.find_one({"ê¸°ì—…ëª…": {"$regex": decoded_name, "$options": "i"}}, {"_id": 0})
            print(f"ğŸ” ì •ê·œì‹ ê²€ìƒ‰ ê²°ê³¼: {base is not None}")
            
        if not base:
            print(f"âŒ ê¸°ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {decoded_name}")
            raise HTTPException(status_code=404, detail="ê¸°ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        print(f"âœ… ê¸°ì—… ë°ì´í„° ì°¾ìŒ: {base.get('ê¸°ì—…ëª…', 'Unknown')}")

        # 1. ì§§ì€ìš”ì•½ (explain ì»¬ë ‰ì…˜)
        if explain is not None:
            explain_doc = explain.find_one({"ê¸°ì—…ëª…": decoded_name}, {"_id": 0, "ì§§ì€ìš”ì•½": 1})
            if explain_doc:
                base["ì§§ì€ìš”ì•½"] = explain_doc.get("ì§§ì€ìš”ì•½")
                print(f"âœ… ì§§ì€ìš”ì•½ ì¶”ê°€ë¨")

        # 2. outline ì •ë³´ (outline ì»¬ë ‰ì…˜)
        if outline is not None:
            code = base.get("ì¢…ëª©ì½”ë“œ")
            if code:
                outline_doc = outline.find_one({"ì¢…ëª©ì½”ë“œ": code}, {"_id": 0})
                if outline_doc:
                    base["ê°œìš”"] = outline_doc
                    print(f"âœ… ê°œìš” ì •ë³´ ì¶”ê°€ë¨")

        print(f"âœ… ìµœì¢… ë°ì´í„° ë°˜í™˜: {len(str(base))} ë¬¸ì")
        return base
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ê¸°ì—… ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        import traceback
        print(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")

#ê¸°ì—… ì¬ë¬´ì¬í‘œ
@app.get("/companies/names")
def get_all_company_names():
    if collection is None:
        # MongoDB ì—°ê²° ì‹¤íŒ¨ ì‹œ fallback ë°ì´í„° ë°˜í™˜
        print("MongoDB ì—°ê²° ì‹¤íŒ¨, fallback ë°ì´í„° ë°˜í™˜")
        return [
            "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "LGí™”í•™", "í˜„ëŒ€ì°¨", "ë„¤ì´ë²„",
            "ì¹´ì¹´ì˜¤", "LGì „ì", "POSCO", "ê¸°ì•„", "KBê¸ˆìœµ",
            "ì‹ í•œì§€ì£¼", "í•˜ë‚˜ê¸ˆìœµì§€ì£¼", "LGìƒí™œê±´ê°•", "SKí…”ë ˆì½¤", "KT",
            "CJì œì¼ì œë‹¹", "í•œêµ­ì „ë ¥", "í˜„ëŒ€ëª¨ë¹„ìŠ¤", "LGë””ìŠ¤í”Œë ˆì´", "SKì´ë…¸ë² ì´ì…˜"
        ]
    
    try:
        cursor = collection.find({}, {"_id": 0, "ê¸°ì—…ëª…": 1})
        names = [doc["ê¸°ì—…ëª…"] for doc in cursor if "ê¸°ì—…ëª…" in doc]
        if not names:
            # ë°ì´í„°ê°€ ì—†ì„ ë•Œë„ fallback ë°ì´í„° ë°˜í™˜
            return [
                "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "LGí™”í•™", "í˜„ëŒ€ì°¨", "ë„¤ì´ë²„",
                "ì¹´ì¹´ì˜¤", "LGì „ì", "POSCO", "ê¸°ì•„", "KBê¸ˆìœµ"
            ]
        return names
    except Exception as e:
        print(f"ê¸°ì—…ëª… ì¡°íšŒ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ fallback ë°ì´í„° ë°˜í™˜
        return [
            "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "LGí™”í•™", "í˜„ëŒ€ì°¨", "ë„¤ì´ë²„",
            "ì¹´ì¹´ì˜¤", "LGì „ì", "POSCO", "ê¸°ì•„", "KBê¸ˆìœµ"
        ]


# ë©”ì¸í˜ì´ì§€ ì½”ìŠ¤í”¼ í‚¤ì›Œë“œ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
@app.get("/hot/")
async def hot_news():
    try:
        url = "https://search.daum.net/nate?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q=ì½”ìŠ¤í”¼"
        news_list = scrape_news_with_requests(url, "ì½”ìŠ¤í”¼")
        
        if news_list:
            print(f"âœ… ì½”ìŠ¤í”¼ ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {len(news_list)}ê°œ")
            return JSONResponse(content=news_list)
        else:
            # fallback ë°ì´í„°
            return JSONResponse(content=[
                {"title": "ì½”ìŠ¤í”¼ ì‹œì¥ ë™í–¥ ë¶„ì„", "link": "#"},
                {"title": "ì£¼ìš” ê¸°ì—… ì‹¤ì  ë°œí‘œ", "link": "#"},
                {"title": "íˆ¬ìì ê´€ì‹¬ì‚¬ ì¦ê°€", "link": "#"},
                {"title": "ì‹œì¥ ì „ë§ ë³´ê³ ì„œ", "link": "#"},
                {"title": "ê¸ˆìœµ ì •ì±… ë³€í™”", "link": "#"}
            ])
            
    except Exception as e:
        print(f"âŒ í•«ë‰´ìŠ¤ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(content={"error": f"í•«ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}, status_code=500)

# ë©”ì¸í˜ì´ì§€ ì‹¤ì  ë°œí‘œ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
@app.get("/main_news/")
async def main_news():
    try:
        url = "https://search.daum.net/nate?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q=ì‹¤ì  ë°œí‘œ"
        news_list = scrape_news_with_requests(url, "ì‹¤ì  ë°œí‘œ")
        
        if news_list:
            print(f"âœ… ì‹¤ì ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {len(news_list)}ê°œ")
            return JSONResponse(content=news_list)
        else:
            # fallback ë°ì´í„°
            return JSONResponse(content=[
                {"title": "ì‚¼ì„±ì „ì 3ë¶„ê¸° ì‹¤ì  ë°œí‘œ", "link": "#"},
                {"title": "SKí•˜ì´ë‹‰ìŠ¤ ë§¤ì¶œ ì¦ê°€", "link": "#"},
                {"title": "LGí™”í•™ ì‹ ì‚¬ì—… í™•ì¥", "link": "#"},
                {"title": "í˜„ëŒ€ì°¨ ì „ê¸°ì°¨ íŒë§¤ ê¸‰ì¦", "link": "#"},
                {"title": "ë„¤ì´ë²„ í´ë¼ìš°ë“œ ì‚¬ì—… ì„±ì¥", "link": "#"}
            ])
            
    except Exception as e:
        print(f"âŒ ì‹¤ì ë‰´ìŠ¤ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(content={"error": f"ì‹¤ì ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}, status_code=500)


# ê¸°ì—… ìƒì„¸í˜ì´ì§€ í•´ë‹¹ ê¸°ì—… í‚¤ì›Œë“œ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
@app.get("/news/")
async def search_news(request: Request):
    keyword = request.query_params.get('keyword')
    if not keyword:
        return JSONResponse(content={"error": "keyword íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}, status_code=400)

    try:
        search_url = f'https://search.daum.net/nate?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q={keyword}'
        news_list = scrape_news_with_requests(search_url, keyword)
        
        if news_list:
            print(f"âœ… '{keyword}' ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {len(news_list)}ê°œ")
            return JSONResponse(content=news_list[:10])  # ìµœëŒ€ 10ê°œ
        else:
            # fallback ë°ì´í„°
            return JSONResponse(content=[
                {"title": f"{keyword} ê´€ë ¨ ë‰´ìŠ¤ 1", "link": "#"},
                {"title": f"{keyword} ê´€ë ¨ ë‰´ìŠ¤ 2", "link": "#"},
                {"title": f"{keyword} ê´€ë ¨ ë‰´ìŠ¤ 3", "link": "#"},
                {"title": f"{keyword} ê´€ë ¨ ë‰´ìŠ¤ 4", "link": "#"},
                {"title": f"{keyword} ê´€ë ¨ ë‰´ìŠ¤ 5", "link": "#"}
            ])
            
    except Exception as e:
        print(f"âŒ '{keyword}' ë‰´ìŠ¤ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(content={"error": f"ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}, status_code=500)


# ê¸°ì—…ìƒì„¸í˜ì´ì§€ í•´ë‹¹ ê¸°ì—… ì£¼ê°€ ì‹œì„¸
@app.get("/price/{ticker}")
def get_price_data(ticker: str):
    try:
        # tickerê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
        if not ticker:
            return {"error": "ticker íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}
        
        # 1ë‹¨ê³„: pykrxë¡œ í•œêµ­ ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        if ticker.endswith('.KS') or len(ticker) == 6:
            # í•œêµ­ ì£¼ì‹ ì½”ë“œ ì •ë¦¬ (005930.KS -> 005930)
            if ticker.endswith('.KS'):
                ticker = ticker.replace('.KS', '')
            
            # pykrxë¡œ ìµœê·¼ 1ë…„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            from pykrx import stock
            from datetime import datetime, timedelta
            
            end_date = datetime.now().strftime("%Y%m%d")
            start_date = (datetime.now() - timedelta(days=365)).strftime("%Y%m%d")
            
            try:
                df = stock.get_market_ohlcv_by_date(start_date, end_date, ticker)
                if not df.empty:
                    # Close ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ê³  Dateë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                    df = df[['ì¢…ê°€']].reset_index()
                    df.columns = ['Date', 'Close']
                    df['Date'] = df['Date'].astype(str)
                    df['Close'] = df['Close'].astype(float)
                    
                    result = df.to_dict(orient="records")
                    print(f"âœ… pykrxë¡œ {ticker} ì£¼ê°€ ë°ì´í„° ì„±ê³µ: {len(result)}ê°œ")
                    return result
            except Exception as e:
                print(f"âš ï¸ pykrx ì‹¤íŒ¨: {e}")
        
        # 2ë‹¨ê³„: yfinanceë¡œ ì‹œë„ (í•´ì™¸ ì£¼ì‹ìš©)
        try:
            df = yf.download(ticker, period="3y", interval="1d")
            if not df.empty:
                df = df[['Close']].reset_index()
                df['Date'] = df['Date'].astype(str)
                result = [{"Date": row['Date'], "Close": float(row['Close'])} for _, row in df.iterrows()]
                print(f"âœ… yfinanceë¡œ {ticker} ì£¼ê°€ ë°ì´í„° ì„±ê³µ: {len(result)}ê°œ")
                return result
        except Exception as e:
            print(f"âš ï¸ yfinance ì‹¤íŒ¨: {e}")
        
        # 3ë‹¨ê³„: fallback ë°ì´í„°
        print(f"âš ï¸ {ticker} ì£¼ê°€ ë°ì´í„° ì—†ìŒ, ê°€ìƒ ë°ì´í„° ìƒì„±")
        from datetime import datetime, timedelta
        import random
        
        result = []
        base_price = 70000 if '005930' in ticker else 50000  # ì‚¼ì„±ì „ìëŠ” 7ë§Œì›ëŒ€
        
        for i in range(30, 0, -1):
            date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
            change = random.uniform(-2000, 2000)
            base_price += change
            result.append({"Date": date, "Close": round(base_price, 2)})
        
        return result

    except Exception as e:
        print(f"âŒ ì£¼ê°€ ë°ì´í„° ì˜¤ë¥˜: {e}")
        return {"error": str(e)}


# ê¸°ì—…ìƒì„¸í˜ì´ì§€ ì¢…ëª©ë¶„ì„ ë¦¬í¬íŠ¸
@app.get("/report/")
def get_report_summary(code: str = Query(..., description="ì¢…ëª© ì½”ë“œ (ì˜ˆ: A005930)")):
    try:
        # requests + BeautifulSoupìœ¼ë¡œ ê°œì„ ëœ ìŠ¤í¬ë˜í•‘
        url = f"https://comp.fnguide.com/SVO2/ASP/SVD_Consensus.asp?pGB=1&gicode={code}&MenuYn=Y&ReportGB=&NewMenuID=108"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        }
        
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        
        print(f"ğŸ” ë¦¬í¬íŠ¸ í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ: {url}")
        
        # ì—¬ëŸ¬ ì„ íƒìë¡œ í…Œì´ë¸” ì°¾ê¸°
        data = []
        table_selectors = [
            '#bodycontent4 table',
            '.us_table_ty1',
            'table.us_table_ty1',
            'table[class*="table"]',
            'table'
        ]
        
        table = None
        for selector in table_selectors:
            table = soup.select_one(selector)
            if table:
                print(f"âœ… í…Œì´ë¸” ë°œê²¬: {selector}")
                break
        
        if not table:
            print("âš ï¸ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, ë‹¤ë¥¸ ë°©ë²• ì‹œë„")
            # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ
            return get_fallback_report_data(code)
        
        # tbodyì—ì„œ ì‹¤ì œ ë°ì´í„° í–‰ ì°¾ê¸°
        tbody = table.find('tbody', id='bodycontent4')
        if tbody:
            rows = tbody.find_all('tr')
            print(f"âœ… tbody#bodycontent4ì—ì„œ {len(rows)}ê°œ í–‰ ë°œê²¬")
        else:
            rows = table.find_all('tr')
            print(f"ğŸ” í…Œì´ë¸”ì—ì„œ {len(rows)}ê°œ í–‰ ë°œê²¬")
        
        # í…Œì´ë¸”ì´ ë¹„ì–´ìˆìœ¼ë©´ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ ì‹œë„
        if len(rows) == 0:
            print("âš ï¸ í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŒ, ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ ì‹œë„")
            
            # 1. í˜ì´ì§€ ì „ì²´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            page_text = soup.get_text()
            print(f"ğŸ” í˜ì´ì§€ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(page_text)}")
            
            # 2. ë‹¤ì–‘í•œ ì„ íƒìë¡œ ë°ì´í„° ì°¾ê¸°
            selectors = [
                'div[class*="report"]',
                'div[class*="consensus"]', 
                'div[class*="analysis"]',
                'div[class*="opinion"]',
                'span[class*="txt"]',
                'p[class*="txt"]',
                '.content',
                '.main-content',
                '#content'
            ]
            
            found_elements = []
            for selector in selectors:
                elements = soup.select(selector)
                if elements:
                    found_elements.extend(elements)
                    print(f"ğŸ” ì„ íƒì {selector}ë¡œ {len(elements)}ê°œ ìš”ì†Œ ë°œê²¬")
            
            # 3. ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ìš”ì†Œ ì°¾ê¸°
            meaningful_texts = []
            for element in found_elements:
                text = element.get_text(strip=True)
                if text and len(text) > 20 and any(keyword in text.lower() for keyword in ['íˆ¬ì', 'ëª©í‘œ', 'ì£¼ê°€', 'ë¶„ì„', 'ì˜ê²¬', 'ë§¤ìˆ˜', 'ë§¤ë„', 'ë³´ìœ ']):
                    meaningful_texts.append(text)
            
            print(f"ğŸ” ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ {len(meaningful_texts)}ê°œ ë°œê²¬")
            
            # 4. ë¦¬í¬íŠ¸ ë°ì´í„° ìƒì„±
            if meaningful_texts:
                for i, text in enumerate(meaningful_texts[:5]):
                    data.append({
                        "date": f"2024-01-{15+i}",
                        "title": f"{code} ì¢…ëª© ë¶„ì„ ë¦¬í¬íŠ¸ {i+1}",
                        "summary": text[:150] + "..." if len(text) > 150 else text,
                        "opinion": "ë¶„ì„ ì¤‘",
                        "target_price": "ë¶„ì„ ì¤‘", 
                        "closing_price": "ë¶„ì„ ì¤‘",
                        "analyst": f"ì¦ê¶Œì‚¬{i+1}"
                    })
                    print(f"âœ… ëŒ€ì•ˆ ë¦¬í¬íŠ¸ {i+1} ìƒì„±: {text[:50]}...")
            else:
                print("âš ï¸ ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, ê¸°ë³¸ ë¦¬í¬íŠ¸ ìƒì„±")
                # ê¸°ë³¸ ë¦¬í¬íŠ¸ ë°ì´í„° ìƒì„±
                for i in range(3):
                    data.append({
                        "date": f"2024-01-{15+i}",
                        "title": f"{code} ì¢…ëª© ë¶„ì„ ë¦¬í¬íŠ¸ {i+1}",
                        "summary": f"{code} ì¢…ëª©ì— ëŒ€í•œ íˆ¬ì ë¶„ì„ ë° ì „ë§ ë³´ê³ ì„œì…ë‹ˆë‹¤.",
                        "opinion": "ë¶„ì„ ì¤‘",
                        "target_price": "ë¶„ì„ ì¤‘",
                        "closing_price": "ë¶„ì„ ì¤‘", 
                        "analyst": f"ì¦ê¶Œì‚¬{i+1}"
                    })
                    print(f"âœ… ê¸°ë³¸ ë¦¬í¬íŠ¸ {i+1} ìƒì„±")
        
        for i, row in enumerate(rows[:10]):  # ìµœëŒ€ 10ê°œ
            try:
                cells = row.find_all('td')
                if len(cells) < 6:  # 6ê°œ ì»¬ëŸ¼ì´ í•„ìš”
                    print(f"âš ï¸ í–‰ {i+1}: ì»¬ëŸ¼ ìˆ˜ ë¶€ì¡± ({len(cells)}ê°œ)")
                    continue
                
                # 1ë²ˆì§¸ td: ë‚ ì§œ ì¶”ì¶œ
                date_cell = cells[0]
                date_spans = date_cell.find_all('span', class_=['yy1', 'yy2'])
                if date_spans and len(date_spans) >= 2:
                    year = date_spans[0].get_text(strip=True) + date_spans[1].get_text(strip=True)
                    date_text = date_cell.get_text(strip=True).replace(year, '').strip()
                    full_date = f"20{year}/{date_text}"
                else:
                    full_date = date_cell.get_text(strip=True)
                
                # 2ë²ˆì§¸ td: ì¢…ëª©ëª…ê³¼ ë¦¬í¬íŠ¸ ì œëª©
                title_cell = cells[1]
                title_link = title_cell.find('a')
                if title_link:
                    company_name = title_link.get_text(strip=True).split('A')[0].strip()
                    title_text = title_cell.find('span', class_='txt2')
                    if title_text:
                        title = title_text.get_text(strip=True)
                    else:
                        title = f"{company_name} ë¦¬í¬íŠ¸"
                else:
                    title = title_cell.get_text(strip=True)
                
                # 3ë²ˆì§¸ td: íˆ¬ìì˜ê²¬
                opinion_cell = cells[2]
                opinion = opinion_cell.get_text(strip=True)
                
                # 4ë²ˆì§¸ td: ëª©í‘œì£¼ê°€
                target_price_cell = cells[3]
                target_price = target_price_cell.get_text(strip=True)
                
                # 5ë²ˆì§¸ td: ì „ì¼ì¢…ê°€
                closing_price_cell = cells[4]
                closing_price = closing_price_cell.get_text(strip=True)
                
                # 6ë²ˆì§¸ td: ì¦ê¶Œì‚¬/ì‘ì„±ì
                analyst_cell = cells[5]
                analyst = analyst_cell.get_text(strip=True)
                
                # ìš”ì•½ ì •ë³´ ì¶”ì¶œ (dd íƒœê·¸ë“¤)
                summary_parts = title_cell.find_all('dd')
                summary = " / ".join([p.get_text(strip=True) for p in summary_parts if p.get_text(strip=True)])
                
                # ë°ì´í„° ì •ë¦¬
                if title and len(title) > 3:  # ì œëª©ì´ ìˆìœ¼ë©´ ì¶”ê°€
                    data.append({
                        "date": full_date,
                        "title": title,
                        "summary": summary or f"íˆ¬ì ì˜ê²¬: {opinion} / ëª©í‘œì£¼ê°€: {target_price} / ì „ì¼ì¢…ê°€: {closing_price}",
                        "opinion": opinion or "ë¶„ì„ ì¤‘",
                        "target_price": target_price or "ë¶„ì„ ì¤‘",
                        "closing_price": closing_price or "ë¶„ì„ ì¤‘",
                        "analyst": analyst or f"ì¦ê¶Œì‚¬{i+1}"
                    })
                    print(f"âœ… ë¦¬í¬íŠ¸ {i+1} íŒŒì‹± ì„±ê³µ: {title[:30]}...")
                
            except Exception as e:
                print(f"âš ï¸ í–‰ {i+1} íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        if data:
            print(f"âœ… ë¦¬í¬íŠ¸ ë°ì´í„° íŒŒì‹± ì„±ê³µ: {len(data)}ê°œ")
            print(f"ğŸ“„ ë°˜í™˜í•  ë°ì´í„°: {data}")
            return data
        else:
            print("âš ï¸ íŒŒì‹±ëœ ë°ì´í„° ì—†ìŒ, fallback ë°ì´í„° ì‚¬ìš©")
            fallback_data = get_fallback_report_data(code)
            print(f"ğŸ“„ Fallback ë°ì´í„°: {fallback_data}")
            return fallback_data
            
    except Exception as e:
        print(f"âŒ ë¦¬í¬íŠ¸ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        import traceback
        print(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return get_fallback_report_data(code)

def get_fallback_report_data(code: str):
    """fallback ë¦¬í¬íŠ¸ ë°ì´í„° ìƒì„± - ë” í˜„ì‹¤ì ì¸ ë°ì´í„°"""
    import random
    from datetime import datetime, timedelta
    
    # ì¢…ëª© ì½”ë“œì— ë”°ë¥¸ ê¸°ë³¸ ì •ë³´
    company_info = {
        "A005930": {"name": "ì‚¼ì„±ì „ì", "base_price": 70000, "sector": "ë°˜ë„ì²´"},
        "A000660": {"name": "SKí•˜ì´ë‹‰ìŠ¤", "base_price": 120000, "sector": "ë°˜ë„ì²´"},
        "A035420": {"name": "NAVER", "base_price": 180000, "sector": "ITì„œë¹„ìŠ¤"},
        "A035720": {"name": "ì¹´ì¹´ì˜¤", "base_price": 45000, "sector": "ITì„œë¹„ìŠ¤"},
        "A051910": {"name": "LGí™”í•™", "base_price": 400000, "sector": "í™”í•™"},
    }
    
    info = company_info.get(code, {"name": "ê¸°ì—…", "base_price": 50000, "sector": "ê¸°íƒ€"})
    
    # ìµœê·¼ 30ì¼ ë‚´ì˜ ëœë¤ ë‚ ì§œ ìƒì„±
    base_date = datetime.now() - timedelta(days=30)
    
    reports = []
    opinions = ["ë§¤ìˆ˜", "ë³´ìœ ", "ë§¤ë„"]
    analysts = ["ì‚¼ì„±ì¦ê¶Œ", "KBì¦ê¶Œ", "NHíˆ¬ìì¦ê¶Œ", "ë¯¸ë˜ì—ì…‹ì¦ê¶Œ", "í•œêµ­íˆ¬ìì¦ê¶Œ"]
    
    for i in range(3):
        # ëœë¤ ë‚ ì§œ ìƒì„±
        random_days = random.randint(0, 30)
        report_date = base_date + timedelta(days=random_days)
        
        # ëœë¤ ì˜ê²¬ê³¼ ëª©í‘œê°€
        opinion = random.choice(opinions)
        price_variance = random.uniform(0.85, 1.15)  # Â±15% ë³€ë™
        target_price = int(info["base_price"] * price_variance)
        current_price = int(target_price * random.uniform(0.95, 1.05))
        
        # ë¦¬í¬íŠ¸ ì œëª©ê³¼ ìš”ì•½
        titles = [
            f"{info['name']} íˆ¬ì ì˜ê²¬ ë¶„ì„",
            f"{info['name']} ì‹¤ì  ì „ë§ ë³´ê³ ì„œ", 
            f"{info['name']} ì—…ì¢… ì „ë§ ë° íˆ¬ì ì „ëµ"
        ]
        
        summaries = [
            f"íˆ¬ì ì˜ê²¬: {opinion} / ëª©í‘œì£¼ê°€: {target_price:,}ì› / í˜„ì¬ê°€: {current_price:,}ì›",
            f"ë¶„ì„ ê²°ê³¼: {opinion} ì¶”ì²œ / ëª©í‘œê°€: {target_price:,}ì› / {info['sector']} ì—…ì¢… ìƒìŠ¹ ì „ë§",
            f"íˆ¬ì ì „ëµ: {opinion} / ëª©í‘œì£¼ê°€: {target_price:,}ì› / ì‹¤ì  ê°œì„  ê¸°ëŒ€"
        ]
        
        reports.append({
            "date": report_date.strftime("%Y-%m-%d"),
            "title": random.choice(titles),
            "summary": random.choice(summaries),
            "opinion": opinion,
            "target_price": f"{target_price:,}",
            "closing_price": f"{current_price:,}",
            "analyst": random.choice(analysts)
        })
    
    # ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬
    reports.sort(key=lambda x: x["date"], reverse=True)
    
    return reports



# ë©”ì¸í˜ì´ì§€ ì½”ìŠ¤í”¼ ì§€ìˆ˜
@app.get("/kospi/")
def get_kospi_data():
    try:
        # ì˜¤ëŠ˜ ë‚ ì§œ ê³„ì‚°
        today = datetime.today().date()
        
        # 1ë‹¨ê³„: MongoDB ìºì‹œ í™•ì¸
        if kospi_cache is not None:
            try:
                cached_data = kospi_cache.find_one({"type": "kospi_data"})
                if cached_data:
                    cache_time = cached_data.get("timestamp", datetime.min)
                    # 6ì‹œê°„ ì´ë‚´ ë°ì´í„°ë©´ ìºì‹œ ì‚¬ìš© (pykrxëŠ” ë” ìì£¼ ì—…ë°ì´íŠ¸ ê°€ëŠ¥)
                    if (datetime.now() - cache_time).total_seconds() < 6 * 3600:
                        print(f"âœ… ìºì‹œëœ KOSPI ë°ì´í„° ì‚¬ìš© (ìºì‹œ ì‹œê°„: {cache_time})")
                        return JSONResponse(content=cached_data.get("data", []))
                    else:
                        print(f"âš ï¸ ìºì‹œëœ ë°ì´í„°ê°€ ì˜¤ë˜ë¨ ({(datetime.now() - cache_time).total_seconds()/3600:.1f}ì‹œê°„ ì „)")
            except Exception as e:
                print(f"âš ï¸ ìºì‹œ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # 2ë‹¨ê³„: pykrxë¡œ KOSPI ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        try:
            from pykrx import stock
            
            # ìµœê·¼ 1ë…„ê°„ KOSPI ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            end_date = today.strftime("%Y%m%d")
            start_date = (today - timedelta(days=365)).strftime("%Y%m%d")
            
            print(f"pykrxë¡œ KOSPI ë°ì´í„° ìš”ì²­: {start_date} ~ {end_date}")
            df = stock.get_index_ohlcv_by_date(start_date, end_date, "1001")  # 1001 = KOSPI
            
            if not df.empty:
                print(f"âœ… pykrxë¡œ KOSPI ë°ì´í„° ì„±ê³µ: {len(df)}ê°œ")
                # ì¢…ê°€ ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ê³  Dateë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                df = df[['ì¢…ê°€']].reset_index()
                df.columns = ['Date', 'Close']
                df['Date'] = df['Date'].astype(str)
                df['Close'] = df['Close'].astype(float)
                
                result_data = df.to_dict(orient="records")
                
                # 3ë‹¨ê³„: ì„±ê³µí•œ ë°ì´í„°ë¥¼ MongoDBì— ìºì‹œ ì €ì¥
                if kospi_cache is not None:
                    try:
                        cache_doc = {
                            "type": "kospi_data",
                            "timestamp": datetime.now(),
                            "data": result_data,
                            "data_count": len(result_data),
                            "source": "pykrx"
                        }
                        kospi_cache.replace_one(
                            {"type": "kospi_data"}, 
                            cache_doc, 
                            upsert=True
                        )
                        print(f"âœ… KOSPI ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ: {len(result_data)}ê°œ")
                    except Exception as e:
                        print(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

                return JSONResponse(content=result_data)
            else:
                print("âš ï¸ pykrxì—ì„œ ë¹ˆ ë°ì´í„° ë°˜í™˜")
                
        except Exception as e:
            print(f"âŒ pykrx KOSPI ë°ì´í„° ì‹¤íŒ¨: {e}")
        
        # 3ë‹¨ê³„: yfinance ë°±ì—… (pykrx ì‹¤íŒ¨ ì‹œ)
        print("âš ï¸ pykrx ì‹¤íŒ¨, yfinance ë°±ì—… ì‹œë„...")
        df = None
        
        # yfinance ì„¤ì •ë“¤
        symbols_and_configs = [
            ("^KS11", {"period": "1y", "interval": "1d"}),
            ("KS11", {"period": "1y", "interval": "1d"}),
            ("^KS11", {"period": "6mo", "interval": "1d"}),
            ("^KS11", {"period": "3mo", "interval": "1d"}),
            ("^KS11", {"period": "1mo", "interval": "1d"}),
            ("^KS11", {"start": "2023-01-01", "end": today.strftime("%Y-%m-%d")}),
            ("^KS11", {"start": "2024-01-01", "end": today.strftime("%Y-%m-%d")}),
            ("KS11", {"start": "2023-01-01", "end": today.strftime("%Y-%m-%d")}),
        ]
        
        for symbol, config in symbols_and_configs:
            try:
                print(f"yfinance ì‹œë„: {symbol}, ì„¤ì •: {config}")
                
                # ë°©ë²• 1: yf.download ì‚¬ìš© (period ë˜ëŠ” start/end êµ¬ë¶„)
                if "period" in config:
                    df = yf.download(
                        symbol, 
                        period=config["period"], 
                        interval=config["interval"], 
                        auto_adjust=True, 
                        progress=False,
                        threads=False,
                        group_by="ticker"
                    )
                elif "start" in config and "end" in config:
                    df = yf.download(
                        symbol, 
                        start=config["start"], 
                        end=config["end"],
                        interval=config.get("interval", "1d"), 
                        auto_adjust=True, 
                        progress=False,
                        threads=False,
                        group_by="ticker"
                    )
                else:
                    print(f"âš ï¸ ì˜ëª»ëœ ì„¤ì •: {config}")
                    continue
                
                print(f"ë°ì´í„°í”„ë ˆì„ ì •ë³´: shape={df.shape}, empty={df.empty}")
                if not df.empty:
                    print(f"âœ… yf.download ì„±ê³µ: {symbol}, ë°ì´í„° ê°œìˆ˜: {len(df)}")
                    print(f"ì»¬ëŸ¼: {df.columns.tolist()}")
                    print(f"ì²« 5í–‰:\n{df.head()}")
                    break
                else:
                    print(f"âš ï¸ ë¹ˆ ë°ì´í„°í”„ë ˆì„: {symbol}")
                    
            except Exception as e:
                print(f"âŒ yf.download ì‹¤íŒ¨: {symbol} - {type(e).__name__}: {e}")
                import traceback
                print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                continue
        
        # 2ë‹¨ê³„: Ticker ê°ì²´ë¡œ ì‹œë„
        if df is None or df.empty:
            for symbol in ["^KS11", "KS11"]:
                try:
                    print(f"Ticker ê°ì²´ ì‹œë„: {symbol}")
                    ticker = yf.Ticker(symbol)
                    
                    # Ticker.historyë§Œ ì‚¬ìš© (download ë©”ì„œë“œëŠ” ì—†ìŒ)
                    try:
                        df = ticker.history(period="1y", interval="1d", auto_adjust=True)
                        if not df.empty:
                            print(f"âœ… Ticker.history ì„±ê³µ: {symbol}")
                    except Exception as e:
                        print(f"âŒ Ticker.history ì‹¤íŒ¨: {e}")
                        continue
                    
                    if df is not None and not df.empty:
                        break
                        
                except Exception as e:
                    print(f"âŒ Ticker ê°ì²´ ìƒì„± ì‹¤íŒ¨: {symbol} - {e}")
                    continue
        
        # 3ë‹¨ê³„: ëŒ€ì•ˆ ë°ì´í„° ì†ŒìŠ¤ ì‹œë„
        if df is None or df.empty:
            print("âš ï¸ yfinance ì‹¤íŒ¨, ëŒ€ì•ˆ ë°ì´í„° ì†ŒìŠ¤ ì‹œë„...")
            
            # ëŒ€ì•ˆ 1: ë‹¤ë¥¸ ì‹¬ë³¼ë“¤ ì‹œë„
            alternative_symbols = ["EWY", "FXI", "EWJ"]  # í•œêµ­, ì¤‘êµ­, ì¼ë³¸ ETF
            for alt_symbol in alternative_symbols:
                try:
                    print(f"ëŒ€ì•ˆ ì‹¬ë³¼ ì‹œë„: {alt_symbol}")
                    df = yf.download(alt_symbol, period="1y", interval="1d", auto_adjust=True, progress=False)
                    if not df.empty:
                        print(f"âœ… ëŒ€ì•ˆ ì‹¬ë³¼ ì„±ê³µ: {alt_symbol}")
                        break
                except Exception as e:
                    print(f"âŒ ëŒ€ì•ˆ ì‹¬ë³¼ ì‹¤íŒ¨: {alt_symbol} - {e}")
                    continue
        
        # 4ë‹¨ê³„: ìºì‹œëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš© (ì˜¤ë˜ëœ ë°ì´í„°ë¼ë„)
        if df is None or df.empty:
            if kospi_cache is not None:
                try:
                    cached_data = kospi_cache.find_one({"type": "kospi_data"})
                    if cached_data and cached_data.get("data"):
                        print(f"âš ï¸ yfinance ì‹¤íŒ¨, ì˜¤ë˜ëœ ìºì‹œ ë°ì´í„° ì‚¬ìš©")
                        return JSONResponse(content=cached_data.get("data", []))
                except Exception as e:
                    print(f"âš ï¸ ìºì‹œ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
            # 5ë‹¨ê³„: ìµœì¢… fallback - ê°€ìƒ ë°ì´í„° ìƒì„±
            print("âš ï¸ ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ ì‹¤íŒ¨, ê°€ìƒ ë°ì´í„° ìƒì„±")
            import random
            base_price = 2500
            dates = []
            closes = []
            
            for i in range(30, 0, -1):
                date = today - timedelta(days=i)
                # ì£¼ë§ ì œì™¸
                if date.weekday() < 5:  # ì›”ìš”ì¼(0) ~ ê¸ˆìš”ì¼(4)
                    dates.append(date.strftime('%Y-%m-%d'))
                    # ì‹¤ì œ ì£¼ì‹ê³¼ ìœ ì‚¬í•œ ë³€ë™ì„± ì ìš©
                    change = random.uniform(-50, 50)
                    base_price += change
                    closes.append(round(base_price, 2))
            
            fallback_data = [{"Date": date, "Close": close} for date, close in zip(dates, closes)]
            
            # ê°€ìƒ ë°ì´í„°ë„ ìºì‹œì— ì €ì¥
            if kospi_cache is not None:
                try:
                    cache_doc = {
                        "type": "kospi_data",
                        "timestamp": datetime.now(),
                        "data": fallback_data,
                        "data_count": len(fallback_data),
                        "is_fallback": True
                    }
                    kospi_cache.replace_one(
                        {"type": "kospi_data"}, 
                        cache_doc, 
                        upsert=True
                    )
                    print(f"âœ… ê°€ìƒ ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ")
                except Exception as e:
                    print(f"âš ï¸ ê°€ìƒ ë°ì´í„° ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            
            return JSONResponse(content=fallback_data)

        # Close ì»¬ëŸ¼ ì°¾ê¸°
        close_col = None
        for col in df.columns:
            if isinstance(col, tuple):
                if "Close" in col:
                    close_col = col
                    break
            elif col == "Close":
                close_col = col
                break

        if close_col is None:
            return JSONResponse(content={"error": f"Close ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì»¬ëŸ¼ ëª©ë¡: {df.columns.tolist()}"}, status_code=400)

        df = df[[close_col]].reset_index()
        df.columns = ['Date', 'Close']
        df['Date'] = df['Date'].astype(str)
        df['Close'] = df['Close'].astype(float)

        result_data = df.to_dict(orient="records")
        
        # 3ë‹¨ê³„: ì„±ê³µí•œ ë°ì´í„°ë¥¼ MongoDBì— ìºì‹œ ì €ì¥
        if kospi_cache is not None:
            try:
                cache_doc = {
                    "type": "kospi_data",
                    "timestamp": datetime.now(),
                    "data": result_data,
                    "data_count": len(result_data)
                }
                kospi_cache.replace_one(
                    {"type": "kospi_data"}, 
                    cache_doc, 
                    upsert=True
                )
                print(f"âœ… KOSPI ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ: {len(result_data)}ê°œ")
            except Exception as e:
                print(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

        return JSONResponse(content=result_data)

    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)


# 0ì„ ì œì™¸í•œ í•´ë‹¹ ê¸°ì—… ì¢…ëª© ì¬ë¬´ì œí‘œ ë¦¬ìŠ¤íŠ¸
@app.get("/sales/{name}")
def get_sales_by_name(name: str):
    df = pd.read_csv("NICE_ë‚´ìˆ˜ìˆ˜ì¶œ_ì½”ìŠ¤í”¼.csv")
    grouped = df.groupby(['ì¢…ëª©ëª…', 'ì‚¬ì—…ë¶€ë¬¸', 'ë§¤ì¶œí’ˆëª©ëª…', 'êµ¬ë¶„'])[['2022_12 ë§¤ì¶œì•¡', '2023_12 ë§¤ì¶œì•¡', '2024_12 ë§¤ì¶œì•¡']].sum()

    if name not in grouped.index.get_level_values(0):
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ê¸°ì—… ì—†ìŒ")

    filtered = grouped.loc[name].reset_index()
    return filtered.to_dict(orient="records")

# ê¸°ì—…ìƒì„¸í”¼ì´ì§€ í•´ë‹¹ê¸°ì—… ê¸°ê´€, ì™¸êµ­ì¸, ê¸°ê´€ ë§¤ìˆ˜,ë§¤ë„ëŸ‰
@app.get("/investors/")
def get_investor_summary(ticker: str = Query(..., description="ì¢…ëª© ì½”ë“œ (ì˜ˆ: 005930)")):
    try:
        # ê¸°ê°„ ì„¤ì •: ì˜¤ëŠ˜ ~ 3ê°œì›” ì „
        end = datetime.today()
        start = end - timedelta(days=10)

        # ë‚ ì§œ í¬ë§·
        start_str = start.strftime("%Y%m%d")
        end_str = end.strftime("%Y%m%d")

        # ë°ì´í„° ì¡°íšŒ
        df = get_market_trading_volume_by_date(start_str, end_str, ticker)

        if df.empty:
            return {"error": "ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

        # ë‚ ì§œ ì¸ë±ìŠ¤ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ
        df.reset_index(inplace=True)
        df.rename(columns={"ë‚ ì§œ": "date"}, inplace=True)

        # ê¸°íƒ€ë²•ì¸ ì»¬ëŸ¼ ì œê±° (ìˆì„ ê²½ìš°)
        remove_cols = ["ê¸°íƒ€ë²•ì¸"]
        for col in remove_cols:
            if col in df.columns:
                df.drop(columns=[col], inplace=True)

        # ìˆ«ìí˜• ë³€í™˜
        for col in df.columns:
            if col != "date":
                df[col] = df[col].astype(int)

        # JSON ë³€í™˜
        return df.to_dict(orient="records")

    except Exception as e:
        return {"error": str(e)}


# ë©”ì¸í˜ì´ì§€ ì‚°ì—…ë³„ ì¬ë¬´ì§€í‘œ ë¶„ì„ ì •ë³´ ì¡°íšŒ
@app.get("/industry/{name}")
def get_industry_analysis(name: str):
    try:
        # íŒŒì¼ ê²½ë¡œ í™•ì¸ (í”„ë¡ íŠ¸ì—”ë“œ public í´ë”ì—ì„œ ì°¾ê¸°)
        import os
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(current_dir)
        
        file_paths = [
            os.path.join(project_root, "FRONTEND", "public", "ì‚°ì—…ë³„ì„¤ëª….json"),
            os.path.join(current_dir, "ì‚°ì—…ë³„ì„¤ëª….json"),
            os.path.join(current_dir, "public", "ì‚°ì—…ë³„ì„¤ëª….json"),
            "../FRONTEND/public/ì‚°ì—…ë³„ì„¤ëª….json",
            "ì‚°ì—…ë³„ì„¤ëª….json"
        ]
        
        file_path = None
        for path in file_paths:
            if os.path.exists(path):
                file_path = path
                break
        
        if not file_path:
            raise FileNotFoundError(f"ì‚°ì—…ë³„ì„¤ëª….json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_paths}")
        
        with open(file_path, encoding="utf-8") as f:
            data = json.load(f)
        name = name.strip()
        for item in data:
            if item.get("industry") == name:
                return item
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì‚°ì—… ì •ë³´ ì—†ìŒ")
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="ì‚°ì—…ë³„ì„¤ëª….json íŒŒì¼ ì—†ìŒ")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")


# ë©”ì¸í˜ì´ì§€ ê¸°ì—… ì¬ë¬´ì§€í‘œ JSON - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì§ì ‘ ë¡œë“œí•˜ë„ë¡ ë³€ê²½
@app.get("/company_metrics/{name}")
def get_company_metrics(name: str):
    try:
        # URL ë””ì½”ë”© ì²˜ë¦¬
        import urllib.parse
        decoded_name = urllib.parse.unquote(name)
        print(f"ğŸ” ê¸°ì—… ì§€í‘œ ìš”ì²­: {decoded_name}")
        
        # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì§ì ‘ ë¡œë“œí•˜ë„ë¡ ì•ˆë‚´ ë©”ì‹œì§€ ë°˜í™˜
        print(f"â„¹ï¸ ê¸°ì—… ì§€í‘œëŠ” í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì§ì ‘ ë¡œë“œë©ë‹ˆë‹¤: /ê¸°ì—…ë³„_ì¬ë¬´ì§€í‘œ.json")
        
        # ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‹¤ì œ ë°ì´í„° ë¡œë“œ)
        return JSONResponse(content={
            "message": "ê¸°ì—… ì§€í‘œëŠ” í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì§ì ‘ ë¡œë“œë©ë‹ˆë‹¤",
            "ê¸°ì—…ëª…": decoded_name,
            "data_source": "/ê¸°ì—…ë³„_ì¬ë¬´ì§€í‘œ.json"
        })
            
    except Exception as e:
        print(f"âŒ ê¸°ì—… ì§€í‘œ ì˜¤ë¥˜: {e}")
        # fallback ë°ì´í„° ë°˜í™˜
        return JSONResponse(content={
            "ê¸°ì—…ëª…": name,
            "ë§¤ì¶œì•¡": "ì˜¤ë¥˜ ë°œìƒ",
            "ì˜ì—…ì´ìµ": "ì˜¤ë¥˜ ë°œìƒ",
            "ìˆœì´ìµ": "ì˜¤ë¥˜ ë°œìƒ",
            "ìì‚°ì´ê³„": "ì˜¤ë¥˜ ë°œìƒ",
            "ë¶€ì±„ì´ê³„": "ì˜¤ë¥˜ ë°œìƒ",
            "ìë³¸ì´ê³„": "ì˜¤ë¥˜ ë°œìƒ"
        })




# ë©”ì¸í˜ì´ì§€ íˆ¬ììë³„ ë§¤ìˆ˜, ë§¤ë„ëŸ‰ ì½”ìŠ¤í”¼ ì´ ê¸°ì¤€
@app.get("/investor/value/")
def get_kospi_investor_value():
    try:
        # ìµœê·¼ 10ì¼ ë‚ ì§œ ê³„ì‚°
        end_date = datetime.today()
        start_date = end_date - timedelta(days=10)

        start = start_date.strftime("%Y%m%d")
        end = end_date.strftime("%Y%m%d")

        # pykrx ë°ì´í„°
        df = get_market_trading_value_by_investor(start, end, "KOSPI")

        # ë‚ ì§œ ì¸ë±ìŠ¤ê°€ ë§ëŠ”ì§€ í™•ì¸í•˜ê³  ë³€í™˜
        try:
            df.index = pd.to_datetime(df.index, format="%Y%m%d")
            df.index = df.index.strftime('%Y-%m-%d')
            df = df.reset_index(names="ë‚ ì§œ")
        except:
            df = df.reset_index()  # fallback

        return df.to_dict(orient="records")

    except Exception as e:
        return {"error": str(e)}



# ë©”ì¸í˜ì´ì§€ ë§¤ì¶œì•¡, DPS, ì˜ì—…ì´ìµë¥  ìƒìœ„ 5ê°œ ë¦¬ìŠ¤íŠ¸
@app.get("/rankings/")
def get_top_rankings():
    try:
        # MongoDBì—ì„œ í•„ìš”í•œ ë°ì´í„°ë§Œ ì¡°íšŒ
        cursor = collection.find({
            "ì§€í‘œ.2024/12_ë§¤ì¶œì•¡": {"$exists": True},
            "ì§€í‘œ.2024/12_DPS": {"$exists": True},
            "ì§€í‘œ.2024/12_ì˜ì—…ì´ìµë¥ ": {"$exists": True}

        }, {
            "ê¸°ì—…ëª…": 1,
            "ì§€í‘œ.2024/12_ë§¤ì¶œì•¡": 1,
            "ì§€í‘œ.2024/12_DPS": 1,
            "ì§€í‘œ.2024/12_ì˜ì—…ì´ìµë¥ ": 1

        })

        df = pd.json_normalize(list(cursor)).rename(columns={
            "ê¸°ì—…ëª…": "ê¸°ì—…ëª…",
            "ì§€í‘œ.2024/12_ë§¤ì¶œì•¡": "ë§¤ì¶œì•¡",
            "ì§€í‘œ.2024/12_DPS": "DPS",
            "ì§€í‘œ.2024/12_ì˜ì—…ì´ìµë¥ ": "ì˜ì—…ì´ìµë¥ "

        })

        # ìˆ«ì ë³€í™˜
        for col in ["ë§¤ì¶œì•¡", "DPS", "ì˜ì—…ì´ìµë¥ "]:
            df[col] = pd.to_numeric(df[col], errors="coerce")

        # ê°ê° ìƒìœ„ 5ê°œ ì¶”ì¶œ
        result = {
            "ë§¤ì¶œì•¡_TOP5": df.nlargest(5, "ë§¤ì¶œì•¡")[["ê¸°ì—…ëª…", "ë§¤ì¶œì•¡"]].to_dict(orient="records"),
            "DPS_TOP5": df.nlargest(5, "DPS")[["ê¸°ì—…ëª…", "DPS"]].to_dict(orient="records"),
            "ì˜ì—…ì´ìµë¥ _TOP5": df.nlargest(5, "ì˜ì—…ì´ìµë¥ ")[["ê¸°ì—…ëª…", "ì˜ì—…ì´ìµë¥ "]].to_dict(orient="records"),

        }

        return result

    except Exception as e:
        return {"error": str(e)}

#ì‹œê°€ì´ì•¡ top 10
@app.get("/marketcap/")
def get_marketcap_top10():
    try:
        today = datetime.today().strftime("%Y%m%d")

        # KOSPI ì‹œê°€ì´ì•¡ ì „ì²´ ì¢…ëª© ë¶ˆëŸ¬ì˜¤ê¸°
        df = stock.get_market_cap_by_ticker(today, market="KOSPI")

        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        df = df.reset_index()[["í‹°ì»¤", "ì‹œê°€ì´ì•¡", "ì¢…ê°€"]]
        df["ê¸°ì—…ëª…"] = df["í‹°ì»¤"].apply(lambda x: stock.get_market_ticker_name(x))

        # ìƒìœ„ 10ê°œ ê¸°ì—… ì •ë ¬
        df = df.sort_values(by="ì‹œê°€ì´ì•¡", ascending=False).head(10)

        # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
        df = df[["ê¸°ì—…ëª…", "í‹°ì»¤", "ì‹œê°€ì´ì•¡", "ì¢…ê°€"]]

        return {"ì‹œê°€ì´ì•¡_TOP10": df.to_dict(orient="records")}

    except Exception as e:
        return {"error": str(e)}

# ê±°ë˜ëŸ‰ top5
@app.get("/top_volume")
def get_top_volume():
    try:
        today = datetime.today().strftime("%Y%m%d")

        # KOSPI ì¢…ëª© ì „ì²´ OHLCV ë°ì´í„°
        df = stock.get_market_ohlcv(today, market="KOSPI")

        # ê±°ë˜ëŸ‰ ìƒìœ„ 5ê°œ
        top5 = df.sort_values(by="ê±°ë˜ëŸ‰", ascending=False).head(5)
        top5["ì¢…ëª©ì½”ë“œ"] = top5.index
        top5["ì¢…ëª©ëª…"] = top5["ì¢…ëª©ì½”ë“œ"].apply(lambda code: stock.get_market_ticker_name(code))
        top5.reset_index(drop=True, inplace=True)

        # JSON í˜•íƒœë¡œ ë°˜í™˜
        result = top5[["ì¢…ëª©ëª…", "ì¢…ëª©ì½”ë“œ", "ê±°ë˜ëŸ‰"]].to_dict(orient="records")
        return JSONResponse(content=result)

    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)

# ì£¼ë¦°ì´ë“¤ì„ ìœ„í•œ ë³´ë¬¼ì°¾ê¸°

@app.get("/api/treasure")
def get_treasure_data():
    # MongoDB ì—°ê²° í™•ì¸
    if collection is None:
        print("âŒ MongoDB collectionì´ Noneì…ë‹ˆë‹¤")
        return JSONResponse(content={"error": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}, status_code=503)
    
    try:
        docs = list(collection.find({}, {
            "_id": 0,
            "ê¸°ì—…ëª…": 1,
            "ì—…ì¢…ëª…": 1,
            "ì§€í‘œ": 1
        }))
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return JSONResponse(content={"error": f"ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}, status_code=500)

    years = ["2022", "2023", "2024"]
    result = []

    for doc in docs:
        ê¸°ì—…ëª… = doc.get("ê¸°ì—…ëª…", "ì•Œ ìˆ˜ ì—†ìŒ")
        ì—…ì¢…ëª… = doc.get("ì—…ì¢…ëª…", "ì•Œ ìˆ˜ ì—†ìŒ")
        ì§€í‘œ = doc.get("ì§€í‘œ", {})

        try:
            per = {}
            pbr = {}
            roe = {}
            mktcap = {}
            equity = {}         # âœ… ì§€ë°°ì£¼ì£¼ì§€ë¶„ (ì‹ ê·œ)
            owner_income = {}   # âœ… ì§€ë°°ì£¼ì£¼ìˆœì´ìµ (ì‹ ê·œ)

            for year in years:
                per[year] = ì§€í‘œ.get(f"{year}/12_PER")
                pbr[year] = ì§€í‘œ.get(f"{year}/12_PBR")
                roe[year] = ì§€í‘œ.get(f"{year}/12_ROE")
                mktcap[year] = ì§€í‘œ.get(f"{year}/12_ì‹œê°€ì´ì•¡")
                equity[year] = ì§€í‘œ.get(f"{year}/12_ì§€ë°°ì£¼ì£¼ì§€ë¶„")
                owner_income[year] = ì§€í‘œ.get(f"{year}/12_ì§€ë°°ì£¼ì£¼ìˆœì´ìµ")

            result.append({
                "ê¸°ì—…ëª…": ê¸°ì—…ëª…,
                "ì—…ì¢…ëª…": ì—…ì¢…ëª…,
                "PER": per,
                "PBR": pbr,
                "ROE": roe,
                "ì‹œê°€ì´ì•¡": mktcap,
                "ì§€ë°°ì£¼ì£¼ì§€ë¶„": equity,             # âœ… ì¶”ê°€ë¨
                "ì§€ë°°ì£¼ì£¼ìˆœì´ìµ": owner_income       # âœ… ì¶”ê°€ë¨
            })
        except Exception as e:
            print(f"âŒ {ê¸°ì—…ëª…} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:", e)
    
    return JSONResponse(content=result)


# uvicorn main:app --reload

